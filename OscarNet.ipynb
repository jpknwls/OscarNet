{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OscarNet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "from keras import regularizers\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Activation,Reshape, Flatten, Conv2D, Dropout, BatchNormalization, Input, MaxPooling2D, Conv2DTranspose\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import os, os.path\n",
    "from keras.models import model_from_json\n",
    "import sklearn\n",
    "from sklearn.metrics import e, auc, roc_auc_score\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "#from scipy.misc import imread\n",
    "#from scipy.misc import imshow\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://cs231n.github.io/transfer-learning/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing\n",
    "\n",
    "rotation_range is a value in degrees (0-180), a range within which to randomly rotate pictures\n",
    "\n",
    "width_shift and height_shift are ranges (as a fraction of total width or height) within which to randomly translate pictures vertically or horizontally\n",
    "\n",
    "rescale is a value by which we will multiply the data before any other processing. Our original images consist in RGB coefficients in the 0-255, but such values would be too high for our models to process (given a typical learning rate), so we target values between 0 and 1 instead by scaling with a 1/255. factor.\n",
    "\n",
    "shear_range is for randomly applying shearing transformations\n",
    "\n",
    "zoom_range is for randomly zooming inside pictures\n",
    "\n",
    "horizontal_flip is for randomly flipping half of the images horizontally --relevant when there are no assumptions of horizontal assymetry (e.g. real-world pictures).\n",
    "\n",
    "fill_mode is the strategy used for filling in newly created pixels, which can appear after a rotation or a width/height shift."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest')\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2, \n",
    "        #zca_epsilon=True,\n",
    "        #featurewise_center = True,\n",
    "        #zca_whitening=True, # apply ZCA whitening\n",
    "        rotation_range=20, # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        width_shift_range=0.2, # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.2, # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=True, # randomly flip images\n",
    "        vertical_flip=False) # randomly flip images\n",
    "\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        'dataset_resized/train',  \n",
    "        target_size=(224, 224),  \n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')  \n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        'dataset_resized/validation',\n",
    "        target_size=(224, 224),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_dataset = 2258\n",
    "itr = train_datagen.flow_from_directory(\n",
    "        'dataset_resized/train',  \n",
    "        target_size=(224, 224),  \n",
    "        batch_size=len_dataset,\n",
    "        class_mode='categorical')  \n",
    "\n",
    "X, y = itr.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ImageNet Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_vgg_model(filename):\n",
    "    json_file = open(filename, 'r')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    loaded_model = model_from_json(loaded_model_json)\n",
    "    loaded_model.layers.pop()\n",
    "    loaded_model.layers.pop()\n",
    "    loaded_model.layers.pop()\n",
    "    return_model = Sequential()\n",
    "    for layer in loaded_model.layers:\n",
    "        return_model.add(layer)\n",
    "    return return_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(filename, model):\n",
    "    model_json = model.to_json()\n",
    "    with open(filename, \"w\") as json_file:\n",
    "        json_file.write(model_json)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_model = keras.applications.vgg19.VGG19(include_top=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet50_model = keras.applications.resnet50.ResNet50(include_top=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incep_model = keras.applications.inception_resnet_v2.InceptionResNetV2(include_top=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt_model = vgg_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "alt_model.layers.pop()\n",
    "alt_model.layers.pop()\n",
    "alt_model.layers.pop()\n",
    "#alt_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#alt_model.summary()\n",
    "save_model(\"models/vgg.json\", vgg_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers_retrain = len(alt_model.layers)\n",
    "num_layers_retrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in alt_model.layers[:num_layers_retrain]:\n",
    "    layer.trainable = False\n",
    "    # how many FC layers and what size \n",
    "# what activations should we use\n",
    "# what is the output size\n",
    "# \n",
    "output = alt_model.layers[len(alt_model.layers)-1].output_shape\n",
    "output                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer Network Architectures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 7\n",
    "\n",
    "transfer_net_test = Sequential()\n",
    "transfer_net_test.add(Dense(256, input_shape = output,activation='relu'))\n",
    "transfer_net_test.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_test = load_vgg_model('models/vgg.json')\n",
    "vgg_test.add(transfer_net_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = keras.optimizers.Adam(lr=.001, beta_1=0.9, beta_2=0.999, epsilon=.1, decay=0.0001)\n",
    "\n",
    "vgg_test.compile(loss='categorical_crossentropy',\n",
    "          optimizer=adam,\n",
    "          metrics=['categorical_accuracy'])\n",
    "\n",
    "vgg_test.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=100, \n",
    "        epochs=10,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lessons:\n",
    "    - Try BatchNormalization\n",
    "    - Try Dropout\n",
    "    - Try increasing layer size\n",
    "    - Try increasing network depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Network 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transfer_network(params, output): \n",
    "    transfer_net = Sequential()\n",
    "    transfer_net.add(Dense(params['first_layer'], input_shape = output,activation='relu', kernel_initializer='glorot_normal', bias_initializer='zeros', kernel_regularizer=regularizers.l2(params['reg']),))\n",
    "    transfer_net.add(Dropout(params['dropout']))\n",
    "    transfer_net.add(BatchNormalization())\n",
    "    for layer in range(0,params['extra_layers']):\n",
    "            transfer_net.add(Dense(params['first_layer'] / 2, input_shape = output,activation='relu', kernel_initializer='glorot_normal', bias_initializer='zeros', kernel_regularizer=regularizers.l2(params['reg']),))\n",
    "            transfer_net.add(Dropout(params['dropout']))\n",
    "            transfer_net.add(BatchNormalization())\n",
    "                                  \n",
    "    transfer_net.add(Dense(7, activation='softmax', kernel_initializer='zeros', bias_initializer='zeros'))\n",
    "    return transfer_net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Transfer Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(x, generator, params):\n",
    "\n",
    "    adam = keras.optimizers.Adam(lr=params['lr'], beta_1=0.9, beta_2=0.999, epsilon=params['epsilon'], decay=0.0001)\n",
    "\n",
    "    x.compile(loss='categorical_crossentropy',\n",
    "              optimizer=adam,\n",
    "              metrics=['categorical_accuracy'])\n",
    "\n",
    "    return x.fit_generator(\n",
    "            generator,\n",
    "            steps_per_epoch=params['steps'], \n",
    "            epochs=params['epochs'],\n",
    "            validation_data=validation_generator,\n",
    "            validation_steps=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'lr': .005,\n",
    "    'epsilon': .1,\n",
    "    'epochs' : 10,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_generator(batch_size, datagen):\n",
    "    return datagen.flow_from_directory(\n",
    "            'dataset_resized/train', \n",
    "            target_size=(224, 224),  \n",
    "            batch_size=batch_size,\n",
    "            class_mode='categorical')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {\n",
    "     'lrs': [.0005, .001, .005, .01, .1],\n",
    "     'layer_size':[64, 128, 256],\n",
    "     'batch_size': [16, 24, 32, 64],\n",
    "     'epochs': [5],\n",
    "     'dropout': [.2, .4, .6, .8],\n",
    "     'epsilons': [.1, .25, .5, .75, 1],\n",
    "     'losses': ['categorical_crossentropy'],\n",
    "     'regularizer': [.01, .02, .05, .1, .5],\n",
    "  \n",
    " }\n",
    "\n",
    "\n",
    "for size in param['layer_size']:\n",
    "    for d in param['dropout']:\n",
    "        for reg in param['regularizer']:\n",
    "            x = load_vgg_model('models/vgg.json')\n",
    "            net_params = {\n",
    "                'first_layer': 256,\n",
    "                'reg': reg,\n",
    "                'dropout': d,\n",
    "                'extra_layers' : 0\n",
    "            }\n",
    "            x.add(transfer_network(net_params, output))\n",
    "            Wsave = x.get_weights()\n",
    "            for batch_size in params['batch_sizes']:\n",
    "                train_generator = load_generator(batch_size, train_datagen) \n",
    "                for lr in params['lrs']:\n",
    "                    for epsilon in params['epsilons']:\n",
    "                        print(\"-----------------------\")\n",
    "                        print(\" \")\n",
    "                        print(batch_size, lr, epsilon)\n",
    "                        params = {\n",
    "                            'lr': lr,\n",
    "                            'epsilon': epsilon,\n",
    "                            'steps': 30,\n",
    "                            'epochs' : 10,\n",
    "                        }\n",
    "                        x.set_weights(Wsave)\n",
    "                        output = train_model(x, train_generator, params)\n",
    "                        print(\"-----------------------\")\n",
    "                        print(\" \")\n",
    "                        outputs.append(output)          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for output in outputs:\n",
    "    print(output.history[\"categorical_accuracy\"], output.history[\"loss\"], output.history[\"val_categorical_accuracy\"], output.history[\"val+loss\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What did we learn?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A larger mini-batch leads to better, faster results (in terms of epochs). However, the smaller batches ran quicker. Across all batches, we saw loss consistently decrease and accuracy consistently increase as the epoch increased, so we decided to balance speed of training with a larger batch size and chose a mini-batch size of 32.\n",
    "\n",
    "For our lr, we saw that a higher learning rate led to faster, but more variable training. We fonud that learning rates between .001 and .0001 returned good results. We decided to use different learning rates based on what stage of training we were at, as a way to control the rate of training. \n",
    "\n",
    "For our epsilon, we saw that 0 returned nan for loss, and was not a viable option. Upon investgation, we found .5 to be the best parameter for this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting Training Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(\"ggplot\")\n",
    "def plot_curves(outputs, N, name, filename):\n",
    "    plt.figure()\n",
    "    plt.plot(np.arange(0, N), outputs.history[\"loss\"], label=\"train_loss\")\n",
    "    plt.plot(np.arange(0, N), outputs.history[\"val_loss\"], label=\"val_loss\")\n",
    "    plt.xlabel(\"Epoch #\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(name)\n",
    "    plt.legend(loc=\"lower left\")\n",
    "    plt.savefig(filename+\"loss\")\n",
    "    plt.figure()\n",
    "    plt.plot(np.arange(0, N), outputs.history[\"categorical_accuracy\"], label=\"train_acc\")\n",
    "    plt.plot(np.arange(0, N), outputs.history[\"val_categorical_accuracy\"], label=\"val_acc\")\n",
    "    plt.title(name)\n",
    "    plt.xlabel(\"Epoch #\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.legend(loc=\"lower left\")\n",
    "    plt.savefig(filename+\"acc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_stats(output, name):\n",
    "    loss_history = output.history[\"loss\"]\n",
    "    val_loss_history = output.history[\"val_loss\"]\n",
    "    acc_history = output.history[\"categorical_accuracy\"]\n",
    "    val_acc_history = output.history[\"val_categorical_accuracy\"]\n",
    "    numpy_loss_history = np.array(loss_history)\n",
    "    np.savetxt(\"loss_history\" + name + \".txt\", numpy_loss_history, delimiter=\",\")\n",
    "    numpy_val_loss_history = np.array(val_loss_history)\n",
    "    np.savetxt(\"val_loss_history\" + name + \".txt\", numpy_val_loss_history, delimiter=\",\")\n",
    "    numpy_acc_history = np.array(acc_history)\n",
    "    np.savetxt(\"acc_history\" + name + \".txt\", numpy_acc_history, delimiter=\",\")\n",
    "    numpy_val_acc_history = np.array(val_acc_history)\n",
    "    np.savetxt(\"val_acc_history\" + name + \".txt\", numpy_val_acc_history, delimiter=\",\")\n",
    "    trained_model.save_weights('weights_shorttrain1.h5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Short Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = load_vgg_model('models/vgg.json')\n",
    "\n",
    "for l in x.layers:\n",
    "    l.trainable = False\n",
    "\n",
    "output = x.layers[len(x.layers)-1].output_shape\n",
    "\n",
    "net_params = {\n",
    "    'first_layer': 256,\n",
    "    'reg': 0,\n",
    "    'dropout': .6,\n",
    "    'extra_layers' : 0\n",
    "}\n",
    "\n",
    "params = {\n",
    "    'lr': .0001,\n",
    "    'epsilon': .1,\n",
    "    'steps': len_dataset/32,\n",
    "    'epochs' : 10,\n",
    "}\n",
    "\n",
    "x.add(transfer_network(net_params, output))\n",
    "\n",
    "short_output = train_model(x, train_generator, params  )\n",
    "\n",
    "save_stats(short_output, \"shorttrain\")\n",
    "\n",
    "x.save_weights('weights/weights_shorttrain_updated.h5')\n",
    "\n",
    "plot_curves(short_output, params['epoch'], \"Short Training with learning rate .005\", \"plots/shorttrain\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Medium Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = load_vgg_model('models/vgg.json')\n",
    "\n",
    "for l in x.layers:\n",
    "    l.trainable = False\n",
    "\n",
    "for l in x.layers[len(x.layers)-3:]:\n",
    "    l.trainable = True\n",
    "\n",
    "output = x.layers[len(x.layers)-1].output_shape\n",
    "\n",
    "net_params = {\n",
    "    'first_layer': 256,\n",
    "    'reg': .01,\n",
    "    'dropout': .6,\n",
    "    'extra_layers' : 0\n",
    "}\n",
    "\n",
    "params = {\n",
    "    'lr': .005,\n",
    "    'epsilon': .5,\n",
    "    'steps': len_dataset/32,\n",
    "    'epochs' : 50,\n",
    "}\n",
    "\n",
    "x.add(transfer_network(net_params, output))\n",
    "\n",
    "x.load_weights('weights/weights_shorttrain_updated.h5')\n",
    "\n",
    "med_output = train_model(x, train_generator, params  )\n",
    "\n",
    "save_stats(med_output, \"shorttrain\")\n",
    "\n",
    "x.save_weights('weights/weights_medtrain_updated.h5')\n",
    "\n",
    "plot_curves(med_output, params['epoch'], \"Short Training with learning rate .005\", \"plots/shorttrain\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Long Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = load_vgg_model('models/vgg.json')\n",
    "\n",
    "for l in x.layers:\n",
    "    l.trainable = False\n",
    "\n",
    "for l in x.layers[len(x.layers)-6:]:    \n",
    "    l.trainable = True\n",
    "\n",
    "output = x.layers[len(x.layers)-1].output_shape\n",
    "\n",
    "net_params = {\n",
    "    'first_layer': 256,\n",
    "    'reg': .025,\n",
    "    'dropout': .6,\n",
    "    'extra_layers' : 0\n",
    "}\n",
    "\n",
    "params = {\n",
    "    'lr': .0001,\n",
    "    'epsilon': .1,\n",
    "    'steps': len_dataset/32,\n",
    "    'epochs' : 200,\n",
    "}\n",
    "\n",
    "x.add(transfer_network(net_params, output))\n",
    "\n",
    "x.load_weights('weights_longtrain2.h5')\n",
    "\n",
    "long_output = train_model(x, train_generator, params  )\n",
    "\n",
    "save_stats(long_output, \"shorttrain\")\n",
    "\n",
    "x.save_weights('weights_longtrain3.h5')\n",
    "\n",
    "plot_curves(long_output, params['epoch'], \"Short Training with learning rate .005\", \"plots/shorttrain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.save_weights('weights_longtrain2.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "x = load_vgg_model('models/vgg.json')\n",
    "\n",
    "\n",
    "net_params = {\n",
    "    'first_layer': 256,\n",
    "    'reg': .05,\n",
    "    'dropout': .6,\n",
    "    'extra_layers' : 0\n",
    "}\n",
    "\n",
    "output = x.layers[len(x.layers)-1].output_shape\n",
    "\n",
    "x.add(transfer_network(net_params, output))\n",
    "\n",
    "x.load_weights('weights_longtrain1.h5')\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        'dataset_resized/validation',\n",
    "        target_size=(224, 224),\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        class_mode='categorical')\n",
    "\n",
    "y_true = []\n",
    "for name in validation_generator.filenames:\n",
    "    if (\"trash\" in name): y_true.append(6)\n",
    "    if (\"metal\" in name): y_true.append(2)\n",
    "    if (\"plastic\" in name): y_true.append(5)\n",
    "    if (\"glass\" in name): y_true.append(1)\n",
    "    if (\"paper\" in name): y_true.append(4)\n",
    "    if (\"waste\" in name): y_true.append(3)\n",
    "    if (\"cardboard\" in name): y_true.append(0)\n",
    "y_true = np.array(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities = x.predict_generator(validation_generator)\n",
    "\n",
    "\n",
    "y_pred = np.array([(np.argmax(l)) for l in probabilities])\n",
    "\n",
    "def softmax(x):\n",
    "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    return e_x / e_x.sum(axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_generator.class_indices.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = confusion_matrix(y_true, y_pred)\n",
    "_max, _min = q.max(), q.min()\n",
    "q = (q - _min)/(_max - _min)\n",
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame = pd.DataFrame(q, index = [i for i in validation_generator.class_indices.keys()],\n",
    "                  columns = [i for i in validation_generator.class_indices.keys()])\n",
    "sn.heatmap(data_frame, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = auc(y_true, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow_p36]",
   "language": "python",
   "name": "conda-env-tensorflow_p36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
